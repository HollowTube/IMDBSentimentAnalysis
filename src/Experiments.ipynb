{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "test_path = \".\\data\\\\test\\\\\"\n",
    "pos_path = \".\\data\\\\train\\\\pos\\\\\"\n",
    "neg_path = \".\\data\\\\train\\\\neg\\\\\"\n",
    "\n",
    "neg_review_list = []\n",
    "pos_review_list = []\n",
    "review_list = []\n",
    "test_set = []\n",
    "\n",
    "for file in os.listdir(neg_path):\n",
    "    file_path = os.path.join(neg_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {}\n",
    "    entry['class'] = 0\n",
    "    entry['raw_txt'] = fh.read()\n",
    "    neg_review_list.append(entry)\n",
    "    fh.close()\n",
    "    \n",
    "for file in os.listdir(pos_path):\n",
    "    file_path = os.path.join(pos_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {}\n",
    "    entry['class'] = 1\n",
    "    entry['raw_txt'] = fh.read()\n",
    "    pos_review_list.append(entry)\n",
    "    fh.close()\n",
    "\n",
    "review_list = pd.DataFrame(neg_review_list + pos_review_list)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Simple text preprocessing using stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "def processing(df):\n",
    "    #lowering and removing punctuation\n",
    "    df['processed'] = df['raw_txt'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
    "        \n",
    "    \n",
    "    #numerical feature engineering\n",
    "    #total length of sentence\n",
    "    df['length'] = df['processed'].apply(lambda x: len(x))\n",
    "    #get number of words\n",
    "    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n",
    "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n",
    "    #get the average word length\n",
    "    df['avg_word_length'] = df['processed'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
    "    #get the average word length\n",
    "    df['commas'] = df['raw_txt'].apply(lambda x: x.count(','))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = processing(review_list)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 raw_txt  \\\n18634  This is the best movie I have ever seen.<br />...   \n1333   My interest in Dorothy Stratten caused me to p...   \n20315  Whilst reading through the comments left for t...   \n6357   'A Smile LIke Yours' is a pathetic comedy that...   \n10496  Alien Hunter: 5 out of 10: Is it me or does ev...   \n\n                                               processed  length  words  \\\n18634  this is the best movie i have ever seenbr br i...     702    141   \n1333   my interest in dorothy stratten caused me to p...     452     78   \n20315  whilst reading through the comments left for t...     858    165   \n6357   a smile like yours is a pathetic comedy that a...    3277    570   \n10496  alien hunter 5 out of 10 is it me or does ever...    2008    372   \n\n       words_not_stopword  avg_word_length  commas  \n18634                  73         5.150685       8  \n1333                   41         6.609756       1  \n20315                  85         5.541176      13  \n6357                  315         6.323810      28  \n10496                 214         5.616822       6  \n18634    1\n1333     0\n20315    1\n6357     0\n10496    0\nName: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_set = [c for c in df.columns.values if c not in ['class']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[feature_set], df['class'], test_size=0.20, random_state=10)\n",
    "print(x_test.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        \n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='processed')),\n",
    "                ('tfidf', TfidfVectorizer( stop_words='english'))\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "features = FeatureUnion([('text', text),\n",
    "                         \n",
    "                         ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from src.Naive_Bayes import NaiveBayes\n",
    "pipeline = Pipeline([('features', features),\n",
    "                     ('classifier', BernoulliNB())])\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "prediction = pipeline.predict(x_test)\n",
    "np.mean(prediction == y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
