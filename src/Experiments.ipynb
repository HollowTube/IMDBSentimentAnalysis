{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pos_path = \".\\\\data\\\\train\\\\pos\\\\\"\n",
    "neg_path = \".\\\\data\\\\train\\\\neg\\\\\"\n",
    "\n",
    "neg_review_list = []\n",
    "pos_review_list = []\n",
    "review_list = []\n",
    "test_set = []\n",
    "\n",
    "for file in os.listdir(neg_path):\n",
    "    file_path = os.path.join(neg_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'class': 0, 'raw_txt': fh.read()}\n",
    "    neg_review_list.append(entry)\n",
    "    fh.close()\n",
    "    \n",
    "for file in os.listdir(pos_path):\n",
    "    file_path = os.path.join(pos_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'class': 1, 'raw_txt': fh.read()}\n",
    "    pos_review_list.append(entry)\n",
    "    fh.close()\n",
    "\n",
    "review_list = pd.DataFrame(neg_review_list + pos_review_list)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_review = pd.DataFrame(neg_review_list[:10]+pos_review_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class                                            raw_txt  \\\n0      0  Story of a man who has unnatural feelings for ...   \n1      0  Airport '77 starts as a brand new luxury 747 p...   \n2      0  This film lacked something I couldn't put my f...   \n3      0  Sorry everyone,,, I know this is supposed to b...   \n4      0  When I was little my parents took me along to ...   \n\n                                           processed  \\\n0  story of a man who has unnatural feelings for ...   \n1  airport 77 starts as a brand new luxury 747 pl...   \n2  this film lacked something i neg_put my finger...   \n3  sorry everyone i know this is supposed to be a...   \n4  when i was little my parents took me along to ...   \n\n                              processed_no_stopwords  sentiment  \n0  story man who has unnatural feelings for pig s...  -0.071759  \n1  airport 77 starts as brand new luxury 747 plan...   0.036677  \n2  this film lacked something i neg_put my finger...   0.079167  \n3  sorry everyone i know this is supposed to be a...   0.043542  \n4  when i was little my parents took me along to ...  -0.055741  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from textblob import Word, TextBlob\n",
    "\n",
    "# stopWords = set(stopwords.words('english'))\n",
    "stopWords=['in','of','at','a','the']\n",
    "\n",
    "def text_processing(txt):\n",
    "    processed = re.sub(r'[^\\w\\s]', '', txt.lower())\n",
    "    #processed = ' '.join([Word(word).lemmatize() for word in processed.split()])\n",
    "    processed = negationHandling(processed.split())\n",
    "    return processed\n",
    "\n",
    "def negationHandling(word_list):\n",
    "    \"\"\"\n",
    "    given an matrix of individual words in order, combine \"negation,\"word\" into\n",
    "    \"neg_word\"\n",
    "    \"\"\"\n",
    "    negation_words = (\"not\", \"hardly\", \"barely\", \"never\", \"neither\", \"scarcely\",\n",
    "                      \"doesn't\", \"doesnt\", \"isn't\", \"isnt\", \"wasn't\", \"wasnt\",\n",
    "                      \"shouldn't\", \"shouldnt\", \"wouldn't\", \"wouldnt\", \"couldn't\",\n",
    "                      \"couldnt\", \"won't\", \"wont\", \"can't\", \"cant\", \"don't\", \"dont\")\n",
    "    for index in range(len(word_list) - 1):\n",
    "        if word_list[index] in negation_words:\n",
    "            word_list[index + 1] = \"neg_\" + word_list[index + 1]\n",
    "    new_list = []\n",
    "    for word in word_list:\n",
    "        if word not in negation_words:\n",
    "            new_list.append(word)\n",
    "    return ' '.join(new_list)\n",
    "\n",
    "\n",
    "def processing(df):\n",
    "    # lowering, removing punctuation and lemmatization\n",
    "    df['processed'] = df['raw_txt'].apply(lambda x: text_processing(x))\n",
    "\n",
    "    # Removing stopwords    \n",
    "    df['processed_no_stopwords'] = df['processed'].apply(\n",
    "        lambda x: ' '.join([t for t in x.split(' ') if t not in stopWords]))\n",
    "    # Sentiment\n",
    "    df['sentiment'] = df['processed_no_stopwords'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "\n",
    "    return df\n",
    "\n",
    "sample = processing(sample_review)\n",
    "df = processing(review_list)\n",
    "print(sample.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5610     devil hunter gained notoriety for fact that it...\n3742     what can i say about seven poundswell i watche...\n5692     this film was so predictable that during entir...\n22213    an attempt to cash on success universals horro...\n23165    dark comedy gallows humor how does one make co...\nName: processed_no_stopwords, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [f for f in df.columns.values if f not in ['class']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['processed_no_stopwords'], df['class'],\n",
    "                                                    test_size=0.20, random_state=10)\n",
    "x_set = df[features]\n",
    "target_set = df['class']\n",
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,3),binary=True)\n",
    "cv.fit(x_train)\n",
    "feature_matrix_train = cv.transform(x_train)\n",
    "feature_matrix_test =  cv.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4597493)\n(20000, 4597493)\n"
     ]
    }
   ],
   "source": [
    "print(feature_matrix_test.shape)\n",
    "print(feature_matrix_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "selector = SelectFromModel(LogisticRegression(),threshold=0.01)\n",
    "selector.fit(feature_matrix_train,y_train)\n",
    "X_test_final = selector.transform(feature_matrix_test)\n",
    "x_train_final = selector.transform(feature_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2964125)\n(5000, 2964125)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_final.shape)\n",
    "print(X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.05: 0.8784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.8802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.8806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(x_train_final, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_test, lr.predict(X_test_final))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model  = LogisticRegression(C = 0.5)\n",
    "final_model.fit(feature_matrix_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('great', 4.073240179349115)\n('best', 2.927497136612272)\n('excellent', 2.8809247427612217)\n('wonderful', 2.5171521886866857)\n('love', 2.47525677090837)\n('loved', 1.9723859747717905)\n('amazing', 1.9475302105225027)\n('perfect', 1.9413853602755384)\n('beautiful', 1.8262653184537212)\n('favorite', 1.8182325826943495)\n('very', 1.7994653789246966)\n('also', 1.776387843232295)\n('is great', 1.7727341530160456)\n('one best', 1.743629830869582)\n('well', 1.738691940903889)\n('recommend', 1.643130673180896)\n('enjoyed', 1.623164150073664)\n('highly', 1.5759168471582203)\n('always', 1.548666207659943)\n('both', 1.5385886660671149)\n('fun', 1.5125325952193178)\n('superb', 1.4512508214821251)\n('world', 1.4286903239300932)\n('very good', 1.423250601624859)\n('brilliant', 1.4182725652162131)\n('fantastic', 1.4122339130606394)\n('life', 1.4005339429993096)\n('enjoy', 1.3824731283394047)\n('years', 1.3769914900574591)\n('my favorite', 1.3734418665960617)\n('job', 1.3731244007578425)\n('shows', 1.368084079623699)\n('will', 1.3424847842382581)\n('it is', 1.3134841110236595)\n('especially', 1.3120780606206035)\n('definitely', 1.3111040583722902)\n('family', 1.2972420248562508)\n('performance', 1.2944442271446575)\n('performances', 1.2837076442214677)\n('is very', 1.28260280825501)\n('classic', 1.2788310366096798)\n('true', 1.2618901262042101)\n('today', 1.2581612558133841)\n('still', 1.2413157677286044)\n('is one', 1.2371156061865856)\n('very well', 1.226690363383402)\n('one my', 1.2112576675399969)\n('different', 1.1849363422668322)\n('recommended', 1.1815070337109002)\n('worth', 1.15180590493425)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bad', -5.089114554865968)\n('worst', -4.6897230776304255)\n('awful', -3.0444489769784395)\n('waste', -2.7713279190241384)\n('nothing', -2.7093266381067793)\n('neg_even', -2.660417101393672)\n('no', -2.6550757116967105)\n('boring', -2.6423353645628502)\n('terrible', -2.4912222334885463)\n('poor', -2.4077775055403143)\n('stupid', -2.3524197624400105)\n('worse', -2.3148956909258596)\n('plot', -2.288048666245941)\n('minutes', -2.211166564981929)\n('script', -2.110830995517214)\n('acting', -2.0916516874423268)\n('horrible', -2.068569300713997)\n('money', -2.0062570417317604)\n('only', -1.9136187163259404)\n('lame', -1.7248845188396813)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:50]:\n",
    "    print (best_positive)\n",
    "    \n",
    "    \n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:20]:\n",
    "    print (best_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
