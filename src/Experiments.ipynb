{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "test_path = \".\\data\\\\test\\\\\"\n",
    "pos_path = \".\\data\\\\train\\\\pos\\\\\"\n",
    "neg_path = \".\\data\\\\train\\\\neg\\\\\"\n",
    "\n",
    "neg_review_list = []\n",
    "pos_review_list = []\n",
    "review_list = []\n",
    "test_set = []\n",
    "\n",
    "for file in os.listdir(neg_path):\n",
    "    file_path = os.path.join(neg_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {}\n",
    "    entry['class'] = 0\n",
    "    entry['raw_txt'] = fh.read()\n",
    "    neg_review_list.append(entry)\n",
    "    fh.close()\n",
    "    \n",
    "for file in os.listdir(pos_path):\n",
    "    file_path = os.path.join(pos_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {}\n",
    "    entry['class'] = 1\n",
    "    entry['raw_txt'] = fh.read()\n",
    "    pos_review_list.append(entry)\n",
    "    fh.close()\n",
    "\n",
    "review_list = pd.DataFrame(neg_review_list[:20] + pos_review_list[:20])\n",
    "review_list_test = pd.DataFrame(neg_review_list[20:30] + pos_review_list[20:30])\n",
    "pos_review_list = pd.DataFrame(pos_review_list)\n",
    "neg_review_list = pd.DataFrame(neg_review_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class                                            raw_txt  \\\n0      0  Story of a man who has unnatural feelings for ...   \n1      0  Airport '77 starts as a brand new luxury 747 p...   \n2      0  This film lacked something I couldn't put my f...   \n3      0  Sorry everyone,,, I know this is supposed to b...   \n4      0  When I was little my parents took me along to ...   \n\n                                           processed  length  words  \\\n0  story of a man who has unnatural feelings for ...     644    112   \n1  airport 77 starts as a brand new luxury 747 pl...    4324    801   \n2  this film lacked something i couldnt put my fi...     776    141   \n3  sorry everyone i know this is supposed to be a...     832    154   \n4  when i was little my parents took me along to ...    2265    395   \n\n   words_not_stopword  avg_word_length  commas  \n0                  63         6.365079       1  \n1                 484         5.456612      16  \n2                  64         6.375000       4  \n3                  79         5.784810      14  \n4                 208         6.596154      26  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "def processing(df):\n",
    "    #lowering and removing punctuation\n",
    "    df['processed'] = df['raw_txt'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
    "    \n",
    "    #numerical feature engineering\n",
    "    #total length of sentence\n",
    "    df['length'] = df['processed'].apply(lambda x: len(x))\n",
    "    #get number of words\n",
    "    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n",
    "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n",
    "    #get the average word length\n",
    "    df['avg_word_length'] = df['processed'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
    "    #get the average word length\n",
    "    df['commas'] = df['raw_txt'].apply(lambda x: x.count(','))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = processing(review_list)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              raw_txt  \\\n2   This film lacked something I couldn't put my f...   \n27  In this \"critically acclaimed psychological th...   \n35  Like one of the previous commenters said, this...   \n30  When I first read Armistead Maupins story I wa...   \n14  This movie must be in line for the most boring...   \n\n                                            processed  length  words  \\\n2   this film lacked something i couldnt put my fi...     776    141   \n27  in this critically acclaimed psychological thr...    2035    339   \n35  like one of the previous commenters said this ...     852    158   \n30  when i first read armistead maupins story i wa...    1511    280   \n14  this movie must be in line for the most boring...     918    178   \n\n    words_not_stopword  avg_word_length  commas  \n2                   64         6.375000       4  \n27                 221         6.153846      29  \n35                  80         5.900000       5  \n30                 151         5.668874       2  \n14                  88         5.409091       6  \n2     0\n27    1\n35    1\n30    1\n14    0\nName: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "set = [c for c in df.columns.values if c  not in ['class']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[set],df['class'], test_size=0.20,random_state=10)\n",
    "print(x_test.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        \n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='processed')),\n",
    "                ('tfidf', TfidfVectorizer( stop_words='english'))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "length =  Pipeline([\n",
    "                ('selector', NumberSelector(key='length')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "features = FeatureUnion([('text', text),\n",
    "                         \n",
    "                         ])\n",
    "features_process = Pipeline([('features', features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "pipeline = Pipeline([('features',features),\n",
    "                     ('classifier', BernoulliNB())])\n",
    "pipeline.fit(x_train,y_train)\n",
    "prediction = pipeline.predict(x_test)\n",
    "np.mean(prediction==y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
