{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "test_path = \".\\data\\\\test\\\\\"\n",
    "pos_path = \".\\data\\\\train\\\\pos\\\\\"\n",
    "neg_path = \".\\data\\\\train\\\\neg\\\\\"\n",
    "\n",
    "neg_review_list = []\n",
    "pos_review_list = []\n",
    "review_list = []\n",
    "test_set = []\n",
    "\n",
    "for file in os.listdir(neg_path):\n",
    "    file_path = os.path.join(neg_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'class': 0, 'raw_txt': fh.read()}\n",
    "    neg_review_list.append(entry)\n",
    "    fh.close()\n",
    "    \n",
    "for file in os.listdir(pos_path):\n",
    "    file_path = os.path.join(pos_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'class': 1, 'raw_txt': fh.read()}\n",
    "    pos_review_list.append(entry)\n",
    "    fh.close()\n",
    "\n",
    "review_list = pd.DataFrame(neg_review_list + pos_review_list)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class                                            raw_txt  \\\n0      0  Story of a man who has unnatural feelings for ...   \n1      0  Airport '77 starts as a brand new luxury 747 p...   \n2      0  This film lacked something I couldn't put my f...   \n3      0  Sorry everyone,,, I know this is supposed to b...   \n4      0  When I was little my parents took me along to ...   \n\n                                           processed  length  words  \\\n0  story of a man who has unnatural feelings for ...     644    112   \n1  airport 77 starts as a brand new luxury 747 pl...    4324    801   \n2  this film lacked something i couldnt put my fi...     776    141   \n3  sorry everyone i know this is supposed to be a...     832    154   \n4  when i was little my parents took me along to ...    2265    395   \n\n   words_not_stopword  avg_word_length  commas  \\\n0                  63         6.365079       1   \n1                 484         5.456612      16   \n2                  64         6.375000       4   \n3                  79         5.784810      14   \n4                 208         6.596154      26   \n\n                                   text_not_stopword  \n0  story man unnatural feelings pig starts openin...  \n1  airport 77 starts brand new luxury 747 plane l...  \n2  film lacked something couldnt put finger first...  \n3  sorry everyone know supposed art film wow hand...  \n4  little parents took along theater see interior...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def processing(df):\n",
    "    # lowering and removing punctuation\n",
    "    df['processed'] = df['raw_txt'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
    "    df['text_not_stopword'] = df['processed'].apply(lambda x: ' '.join([t for t in x.split(' ')if t not in stopWords]))\n",
    "    # numerical feature engineering                                                                                                                              \n",
    "    # total length of sentence\n",
    "    df['length'] = df['processed'].apply(lambda x: len(x))\n",
    "    # get number of words\n",
    "    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n",
    "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ')if t not in stopWords]))\n",
    "    # get the average word length\n",
    "    df['avg_word_length'] = df['processed'].apply(\n",
    "        lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len(\n",
    "            [len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
    "    # get the average word length\n",
    "    df['commas'] = df['raw_txt'].apply(lambda x: x.count(','))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = processing(review_list)\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 raw_txt  \\\n5610   Devil Hunter gained notoriety for the fact tha...   \n3742   What can I say about Seven Pounds...well I wat...   \n5692   This film was so predictable, that during the ...   \n22213  In an attempt to cash in on the success of Uni...   \n23165  Dark comedy? Gallows humor? How does one make ...   \n\n                                               processed  length  words  \\\n5610   devil hunter gained notoriety for the fact tha...    1405    280   \n3742   what can i say about seven poundswell i watche...     727    133   \n5692   this film was so predictable that during the e...    1153    213   \n22213  in an attempt to cash in on the success of uni...    2751    515   \n23165  dark comedy gallows humor how does one make a ...    1179    217   \n\n       words_not_stopword  avg_word_length  commas  \\\n5610                  135         5.118519       9   \n3742                   71         5.802817       0   \n5692                   98         6.010204      10   \n22213                 264         5.696970       1   \n23165                 113         6.079646      14   \n\n                                       text_not_stopword  \n5610   devil hunter gained notoriety fact dpp video n...  \n3742   say seven poundswell watched flight seattle to...  \n5692   film predictable entire time youre hoping obvi...  \n22213  attempt cash success universals horror films m...  \n23165  dark comedy gallows humor one make comedy murd...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [f for f in df.columns.values if f not in ['class']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[features], df['class'],\n",
    "                                                    test_size=0.20, random_state=10)\n",
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TxtPicker(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "text = Pipeline([\n",
    "                ('selector', TxtPicker(key='processed')),\n",
    "                ('tfidf', TfidfVectorizer())\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "length = Pipeline([\n",
    "    ('selector', NumberSelector(key='length')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "words = Pipeline([\n",
    "    ('selector', NumberSelector(key='words')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "words_not_stopword = Pipeline([\n",
    "    ('selector', NumberSelector(key='words_not_stopword')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "avg_word_length = Pipeline([\n",
    "    ('selector', NumberSelector(key='avg_word_length')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "commas = Pipeline([\n",
    "    ('selector', NumberSelector(key='commas')),\n",
    "    ('standard', StandardScaler()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "feats = FeatureUnion([('text', text), \n",
    "                      ('length', length),\n",
    "                      ('words', words),\n",
    "                      ('words_not_stopword', words_not_stopword),\n",
    "                      ('avg_word_length', avg_word_length),\n",
    "                      ('commas', commas)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\nC:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.fit(X, y, **fit_params).transform(X)\nC:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\nC:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.fit(X, y, **fit_params).transform(X)\nC:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\nC:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.fit(X, y, **fit_params).transform(X)\nC:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\nC:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "pipeline = Pipeline([\n",
    "    ('feats', feats),\n",
    "    ('classifier', BernoulliNB()),\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "preds = pipeline.predict(x_test)\n",
    "\n",
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2183,  269],\n       [ 506, 2042]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
