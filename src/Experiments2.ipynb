{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pos_path = \".\\\\data\\\\train\\\\pos\\\\\"\n",
    "neg_path = \".\\\\data\\\\train\\\\neg\\\\\"\n",
    "\n",
    "neg_review_list = []\n",
    "pos_review_list = []\n",
    "review_list = []\n",
    "test_set = []\n",
    "\n",
    "for file in os.listdir(neg_path):\n",
    "    file_path = os.path.join(neg_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'class': 0, 'raw_txt': fh.read()}\n",
    "    neg_review_list.append(entry)\n",
    "    fh.close()\n",
    "    \n",
    "for file in os.listdir(pos_path):\n",
    "    file_path = os.path.join(pos_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'class': 1, 'raw_txt': fh.read()}\n",
    "    pos_review_list.append(entry)\n",
    "    fh.close()\n",
    "\n",
    "review_list = pd.DataFrame(neg_review_list + pos_review_list)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_review = pd.DataFrame(neg_review_list[:10]+pos_review_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class                                            raw_txt  \\\n0      0  Story of a man who has unnatural feelings for ...   \n1      0  Airport '77 starts as a brand new luxury 747 p...   \n2      0  This film lacked something I couldn't put my f...   \n3      0  Sorry everyone,,, I know this is supposed to b...   \n4      0  When I was little my parents took me along to ...   \n\n                                           processed  \\\n0  story of a man who has unnatural feelings for ...   \n1  airport 77 starts as a brand new luxury 747 pl...   \n2  this film lacked something i neg_put my finger...   \n3  sorry everyone i know this is supposed to be a...   \n4  when i was little my parents took me along to ...   \n\n                              processed_no_stopwords  sentiment  \n0  story man who has unnatural feelings for pig s...  -0.071759  \n1  airport 77 starts as brand new luxury 747 plan...   0.036677  \n2  this film lacked something i neg_put my finger...   0.079167  \n3  sorry everyone i know this is supposed to be a...   0.043542  \n4  when i was little my parents took me along to ...  -0.055741  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from textblob import Word, TextBlob\n",
    "\n",
    "# stopWords = set(stopwords.words('english'))\n",
    "stopWords=['in','of','at','a','the']\n",
    "\n",
    "def text_processing(txt):\n",
    "    processed = re.sub(r'[^\\w\\s]', '', txt.lower())\n",
    "    #processed = ' '.join([Word(word).lemmatize() for word in processed.split()])\n",
    "    processed = negationHandling(processed.split())\n",
    "    return processed\n",
    "\n",
    "\n",
    "def negationHandling(word_list):\n",
    "    \"\"\"\n",
    "    given an matrix of individual words in order, combine \"negation,\"word\" into\n",
    "    \"neg_word\"\n",
    "    \"\"\"\n",
    "    negation_words = (\"not\", \"hardly\", \"barely\", \"never\", \"neither\", \"scarcely\",\n",
    "                      \"doesn't\", \"doesnt\", \"isn't\", \"isnt\", \"wasn't\", \"wasnt\",\n",
    "                      \"shouldn't\", \"shouldnt\", \"wouldn't\", \"wouldnt\", \"couldn't\",\n",
    "                      \"couldnt\", \"won't\", \"wont\", \"can't\", \"cant\", \"don't\", \"dont\")\n",
    "    for index in range(len(word_list) - 1):\n",
    "        if word_list[index] in negation_words:\n",
    "            word_list[index + 1] = \"neg_\" + word_list[index + 1]\n",
    "    new_list = []\n",
    "    for word in word_list:\n",
    "        if word not in negation_words:\n",
    "            new_list.append(word)\n",
    "    return ' '.join(new_list)\n",
    "\n",
    "\n",
    "def processing(df):\n",
    "    # lowering, removing punctuation and lemmatization\n",
    "    df['processed'] = df['raw_txt'].apply(lambda x: text_processing(x))\n",
    "\n",
    "    # Removing stopwords    \n",
    "    df['processed_no_stopwords'] = df['processed'].apply(\n",
    "        lambda x: ' '.join([t for t in x.split(' ') if t not in stopWords]))\n",
    "    # Sentiment\n",
    "    df['sentiment'] = df['processed_no_stopwords'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "\n",
    "    return df\n",
    "\n",
    "sample = processing(sample_review)\n",
    "df = processing(review_list)\n",
    "print(sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 raw_txt  \\\n5610   Devil Hunter gained notoriety for the fact tha...   \n3742   What can I say about Seven Pounds...well I wat...   \n5692   This film was so predictable, that during the ...   \n22213  In an attempt to cash in on the success of Uni...   \n23165  Dark comedy? Gallows humor? How does one make ...   \n\n                                               processed  \\\n5610   devil hunter gained notoriety for the fact tha...   \n3742   what can i say about seven poundswell i watche...   \n5692   this film was so predictable that during the e...   \n22213  in an attempt to cash in on the success of uni...   \n23165  dark comedy gallows humor how does one make a ...   \n\n                                  processed_no_stopwords  sentiment  \n5610   devil hunter gained notoriety for fact that it...   0.044228  \n3742   what can i say about seven poundswell i watche...  -0.148864  \n5692   this film was so predictable that during entir...   0.028685  \n22213  an attempt to cash on success universals horro...   0.141726  \n23165  dark comedy gallows humor how does one make co...   0.198120  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [f for f in df.columns.values if f not in ['class']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[features], df['class'],\n",
    "                                                    test_size=0.20, random_state=10)\n",
    "x_set = df[features]\n",
    "target_set = df['class']\n",
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TxtPicker(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "tf_id_feature = Pipeline([\n",
    "    ('selector', TxtPicker(key='processed_no_stopwords')),\n",
    "    ('tfidf', CountVectorizer(ngram_range=(1, 3), binary=True)),\n",
    "    ('top_word_selection', SelectFromModel(LinearSVC()))\n",
    "    # ('selection', SelectPercentile(score_func=chi2, percentile=50))\n",
    "])\n",
    "\n",
    "binary_count_feature = Pipeline([\n",
    "    ('selector', TxtPicker(key='processed')),            \n",
    "    ('count', CountVectorizer(ngram_range=(1, 3),binary=True))\n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8828\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "\n",
    "svc_pipeline = Pipeline([\n",
    "    ('features', tf_id_feature),\n",
    "    ('classifier', LinearSVC(C = 0.01))])\n",
    "\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('features', tf_id_feature),\n",
    "    ('classifier', LogisticRegression(C=10))])\n",
    "\n",
    "decision_tree_pipeline = Pipeline([\n",
    "    ('feats', feats_tfid),\n",
    "    ('classifier', tree.DecisionTreeClassifier())])\n",
    "\n",
    "def fit_predict(model):\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    print(np.mean(preds == y_test))\n",
    "    \n",
    "fit_predict(logistic_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False),\n       fit_params=None, iid='warn', n_jobs=None,\n       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 20]},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 20]\n",
    "param_grid = {'C': Cs}\n",
    "x_grid = tf_id_feature.fit_transform(x_train, y_train)\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=4)\n",
    "grid.fit(x_grid, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.90\nBest parameters:  {'C': 10}\nBest estimator:  LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best estimator: \", grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(logistic_pipeline, x_set, target_set, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.882 (+/- 0.01)\n[0.88368 0.88336 0.876   0.88448]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             raw_txt\n0  Thinking that it could only get better was the...\n1  For most people, RoboCop 3 is the film that re...\n2  I'm pretty sure Poe would have considered this...\n3  This is one of those made-for-TV B movies that...\n4  Wallace & Gromit have been around for some tim...\n(25000, 1)\n"
     ]
    }
   ],
   "source": [
    "test_path = \".\\\\data\\\\test\\\\\"\n",
    "test_set = []\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "dir_list = sorted(os.listdir(test_path), key=numericalSort)\n",
    "\n",
    "for file in dir_list:\n",
    "    file_path = os.path.join(test_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'raw_txt': fh.read()}\n",
    "    test_set.append(entry)\n",
    "    fh.close()\n",
    "\n",
    "test_set = pd.DataFrame(test_set)\n",
    "print(test_set.head())\n",
    "print(test_set.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  Xt = transform.transform(Xt)\nC:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  Xt = transform.transform(Xt)\nC:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  Xt = transform.transform(Xt)\nC:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             raw_txt  \\\n0  Thinking that it could only get better was the...   \n1  For most people, RoboCop 3 is the film that re...   \n2  I'm pretty sure Poe would have considered this...   \n3  This is one of those made-for-TV B movies that...   \n4  Wallace & Gromit have been around for some tim...   \n\n                                           processed  \\\n0  thinking that it could only get better was the...   \n1  for most people robocop 3 is the film that rea...   \n2  im pretty sure poe would have considered this ...   \n3  this is one of those madefortv b movies that i...   \n4  wallace  gromit have been around for some time...   \n\n                                   text_not_stopword  length  words  \\\n0  thinking could get better worst assumption eve...     541    106   \n1  people robocop 3 film really big disgrace robo...    5125    998   \n2  im pretty sure poe would considered travesty f...     336     58   \n3  one madefortv b movies awful kind endearsbr br...     264     51   \n4  wallace  gromit around time first foray onto s...    1489    273   \n\n   words_not_stopword  avg_word_length  commas  \n0                  54         5.444444       3  \n1                 504         5.438492      66  \n2                  33         6.151515       5  \n3                  28         5.321429       1  \n4                 146         5.876712      15  \n   Category\n0         0\n1         0\n2         0\n3         0\n4         1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_set = processing(test_set)\n",
    "\n",
    "test_predictions = pipeline.predict(test_set)\n",
    "\n",
    "prediction_df = pd.DataFrame(test_predictions)\n",
    "\n",
    "prediction_df.columns = ['Category']\n",
    "print(test_set.head())\n",
    "print(prediction_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = prediction_df.to_csv (r'.\\test_results.csv', header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
