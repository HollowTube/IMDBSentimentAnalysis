{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pos_path = \".\\\\data\\\\train\\\\pos\\\\\"\n",
    "neg_path = \".\\\\data\\\\train\\\\neg\\\\\"\n",
    "\n",
    "neg_review_list = []\n",
    "pos_review_list = []\n",
    "review_list = []\n",
    "test_set = []\n",
    "\n",
    "for file in os.listdir(neg_path):\n",
    "    file_path = os.path.join(neg_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'class': 0, 'raw_txt': fh.read()}\n",
    "    neg_review_list.append(entry)\n",
    "    fh.close()\n",
    "    \n",
    "for file in os.listdir(pos_path):\n",
    "    file_path = os.path.join(pos_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'class': 1, 'raw_txt': fh.read()}\n",
    "    pos_review_list.append(entry)\n",
    "    fh.close()\n",
    "\n",
    "review_list = pd.DataFrame(neg_review_list + pos_review_list)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_review = pd.DataFrame(neg_review_list[:10]+pos_review_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class                                            raw_txt  \\\n0      0  Story of a man who has unnatural feelings for ...   \n1      0  Airport '77 starts as a brand new luxury 747 p...   \n2      0  This film lacked something I couldn't put my f...   \n3      0  Sorry everyone,,, I know this is supposed to b...   \n4      0  When I was little my parents took me along to ...   \n\n                                           processed  \\\n0  story of a man who ha unnatural feeling for a ...   \n1  airport 77 start a a brand new luxury 747 plan...   \n2  this film lacked something i couldnt put my fi...   \n3  sorry everyone i know this is supposed to be a...   \n4  when i wa little my parent took me along to th...   \n\n                              processed_no_stopwords  length  words  \\\n0  story man ha unnatural feeling pig start openi...   635.0  112.0   \n1  airport 77 start brand new luxury 747 plane lo...  4218.0  773.0   \n2  film lacked something couldnt put finger first...   766.0  141.0   \n3  sorry everyone know supposed art film wow hand...   822.0  154.0   \n4  wa little parent took along theater see interi...  2235.0  395.0   \n\n   words_not_stopword  words_stopword  avg_word_length  upper  sentiment  \n0                64.0            48.0         6.203125    2.0  -0.067593  \n1               459.0           314.0         5.623094   14.0   0.067934  \n2                68.0            73.0         6.044118    3.0   0.025000  \n3                83.0            71.0         5.530120    3.0   0.027696  \n4               213.0           182.0         6.384977    9.0  -0.081056  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from textblob import Word, TextBlob\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def text_processing(txt):\n",
    "    processed = re.sub(r'[^\\w\\s]', '', txt.lower())\n",
    "    processed = ' '.join([Word(word).lemmatize() for word in processed.split()])\n",
    "    return processed\n",
    "\n",
    "\n",
    "def processing(df):\n",
    "    # lowering, removing punctuation and lemmatization\n",
    "    df['processed'] = df['raw_txt'].apply(lambda x: text_processing(x))\n",
    "\n",
    "    # Removing stopwords    \n",
    "    df['processed_no_stopwords'] = df['processed'].apply(lambda x: ' '.join([t for t in x.split(' ')if t not in stopWords]))\n",
    "                                        \n",
    "    # total length of sentence in characters\n",
    "    df['length'] = df['processed'].apply(lambda x: float(len(x)))\n",
    "    \n",
    "    # get number of words\n",
    "    df['words'] = df['processed'].apply(lambda x: float(len(x.split(' '))))\n",
    "    \n",
    "    # num words that are not stopwords\n",
    "    df['words_not_stopword'] = df['processed'].apply(lambda x: float(len([t for t in x.split(' ')if t not in stopWords])))\n",
    "    \n",
    "    # num words that are stopwords\n",
    "    df['words_stopword'] = df['processed'].apply(lambda x: float(len([t for t in x.split(' ')if t in stopWords])))\n",
    "    \n",
    "    # get the average word length\n",
    "    df['avg_word_length'] = df['processed'].apply(\n",
    "        lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len(\n",
    "            [len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
    "    \n",
    "    # number of upper case words\n",
    "    df['upper'] = df['raw_txt'].apply(lambda x: float(len([x for x in x.split() if x.isupper()])))\n",
    "    \n",
    "    # Sentiment\n",
    "    df['sentiment'] = df['processed_no_stopwords'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "    \n",
    "    return df\n",
    "\n",
    "sample = processing(sample_review)\n",
    "df = processing(review_list)\n",
    "print(sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 raw_txt  \\\n5610   Devil Hunter gained notoriety for the fact tha...   \n3742   What can I say about Seven Pounds...well I wat...   \n5692   This film was so predictable, that during the ...   \n22213  In an attempt to cash in on the success of Uni...   \n23165  Dark comedy? Gallows humor? How does one make ...   \n\n                                               processed  \\\n5610   devil hunter gained notoriety for the fact tha...   \n3742   what can i say about seven poundswell i watche...   \n5692   this film wa so predictable that during the en...   \n22213  in an attempt to cash in on the success of uni...   \n23165  dark comedy gallows humor how doe one make a c...   \n\n                                  processed_no_stopwords  length  words  \\\n5610   devil hunter gained notoriety fact dpp video n...  1379.0  278.0   \n3742   say seven poundswell watched flight seattle to...   714.0  133.0   \n5692   film wa predictable entire time youre hoping o...  1134.0  213.0   \n22213  attempt cash success universal horror film maj...  2692.0  515.0   \n23165  dark comedy gallows humor doe one make comedy ...  1157.0  217.0   \n\n       words_not_stopword  words_stopword  avg_word_length  upper  sentiment  \n5610                135.0           143.0         5.022222    7.0  -0.002381  \n3742                 73.0            60.0         5.589041    4.0  -0.176136  \n5692                102.0           111.0         5.696078    1.0   0.036243  \n22213               270.0           245.0         5.466667    6.0   0.147796  \n23165               115.0           102.0         5.895652    0.0   0.200376  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [f for f in df.columns.values if f not in ['class']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[features], df['class'],\n",
    "                                                    test_size=0.20, random_state=10)\n",
    "x_set = df[features]\n",
    "target_set = df['class']\n",
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class TxtPicker(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "\n",
    "\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import GenericUnivariateSelect,mutual_info_classif\n",
    "\n",
    "tf_id_feature = Pipeline([\n",
    "    ('selector', TxtPicker(key='processed_no_stopwords')),\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('mutual_info', GenericUnivariateSelect(score_func=mutual_info_classif, mode='percentile', param=50))\n",
    "])\n",
    "\n",
    "binary_count_feature = Pipeline([\n",
    "    ('selector', TxtPicker(key='processed')),            \n",
    "    ('count', HashingVectorizer(ngram_range=(1, 2)))\n",
    "])\n",
    "\n",
    "length = Pipeline([\n",
    "    ('selector', NumberSelector(key='length')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "words_not_stopword = Pipeline([\n",
    "    ('selector', NumberSelector(key='words_not_stopword')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "words_stopword = Pipeline([\n",
    "    ('selector', NumberSelector(key='words_stopword')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "words = Pipeline([\n",
    "    ('selector', NumberSelector(key='words')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "avg_length = Pipeline([\n",
    "    ('selector', NumberSelector(key='avg_word_length')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "sentiment = Pipeline([\n",
    "    ('selector', NumberSelector(key='sentiment')),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "upper = Pipeline([\n",
    "    ('selector', NumberSelector(key='upper')),\n",
    "    ('standard', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats_tfid = FeatureUnion([('text', tf_id_feature),\n",
    "                           ('length', length),\n",
    "                           ('words', words),\n",
    "                           ('avg_length', avg_length),\n",
    "                           ('sentiment', sentiment),\n",
    "                           ('upper', upper),\n",
    "                           ('words_not_stopword', words_not_stopword),\n",
    "                           ('words_stopword', words_stopword)\n",
    "                           ])\n",
    "\n",
    "feats_count = FeatureUnion([('text', binary_count_feature),\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\nC:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "\n",
    "svc_pipeline = Pipeline([\n",
    "    ('feats', feats_tfid),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('feats', feats_tfid),\n",
    "    ('selector', SelectFromModel(LinearSVC())),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "decision_tree_pipeline = Pipeline([\n",
    "    ('feats', feats_tfid),\n",
    "    ('classifier', tree.DecisionTreeClassifier())])\n",
    "\n",
    "naive_bayes_pipeline = Pipeline([\n",
    "    ('feats', feats_tfid),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "\n",
    "def fit_predict(model):\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    print(np.mean(preds == y_test))\n",
    "\n",
    "\n",
    "fit_predict(logistic_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tri-Tin\\Anaconda3\\envs\\LinearRegression\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(svc_pipeline, x_set, target_set, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.840 (+/- 0.02)\n[0.84768 0.8216  0.84464 0.8464 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             raw_txt\n0  Thinking that it could only get better was the...\n1  For most people, RoboCop 3 is the film that re...\n2  I'm pretty sure Poe would have considered this...\n3  This is one of those made-for-TV B movies that...\n4  Wallace & Gromit have been around for some tim...\n(25000, 1)\n"
     ]
    }
   ],
   "source": [
    "test_path = \".\\\\data\\\\test\\\\\"\n",
    "test_set = []\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "dir_list = sorted(os.listdir(test_path), key=numericalSort)\n",
    "\n",
    "for file in dir_list:\n",
    "    file_path = os.path.join(test_path, file)\n",
    "    fh = open(file_path, 'r', encoding=\"utf8\")\n",
    "    entry = {'raw_txt': fh.read()}\n",
    "    test_set.append(entry)\n",
    "    fh.close()\n",
    "\n",
    "test_set = pd.DataFrame(test_set)\n",
    "print(test_set.head())\n",
    "print(test_set.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  Xt = transform.transform(Xt)\nC:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  Xt = transform.transform(Xt)\nC:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  Xt = transform.transform(Xt)\nC:\\Users\\HollowTube\\Anaconda3\\envs\\MiniProject1\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             raw_txt  \\\n0  Thinking that it could only get better was the...   \n1  For most people, RoboCop 3 is the film that re...   \n2  I'm pretty sure Poe would have considered this...   \n3  This is one of those made-for-TV B movies that...   \n4  Wallace & Gromit have been around for some tim...   \n\n                                           processed  \\\n0  thinking that it could only get better was the...   \n1  for most people robocop 3 is the film that rea...   \n2  im pretty sure poe would have considered this ...   \n3  this is one of those madefortv b movies that i...   \n4  wallace  gromit have been around for some time...   \n\n                                   text_not_stopword  length  words  \\\n0  thinking could get better worst assumption eve...     541    106   \n1  people robocop 3 film really big disgrace robo...    5125    998   \n2  im pretty sure poe would considered travesty f...     336     58   \n3  one madefortv b movies awful kind endearsbr br...     264     51   \n4  wallace  gromit around time first foray onto s...    1489    273   \n\n   words_not_stopword  avg_word_length  commas  \n0                  54         5.444444       3  \n1                 504         5.438492      66  \n2                  33         6.151515       5  \n3                  28         5.321429       1  \n4                 146         5.876712      15  \n   Category\n0         0\n1         0\n2         0\n3         0\n4         1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_set = processing(test_set)\n",
    "\n",
    "test_predictions = pipeline.predict(test_set)\n",
    "\n",
    "prediction_df = pd.DataFrame(test_predictions)\n",
    "\n",
    "prediction_df.columns = ['Category']\n",
    "print(test_set.head())\n",
    "print(prediction_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = prediction_df.to_csv (r'.\\test_results.csv', header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
